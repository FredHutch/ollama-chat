# Licensed under the MIT License
# https://github.com/craigahobbs/ollama-chat/blob/main/LICENSE

include <args.mds>
include <forms.mds>


# The Ollama Chat application main entry point
async function ollamaChatMain():
    args = argsParse(ollamaChatArguments)
    model = objectGet(args, 'model')
    chatId = objectGet(args, 'id')
    prompt = objectGet(args, 'prompt')

    # Start a chat?
    if prompt != null:
        ollamaChatStartChat(model, prompt)
        return
    endif

    # Render the chat page
    if chatId != null:
        ollamaChatPage(args)
        return
    endif

    # Render the index page
    ollamaChatIndexPage(args)
endfunction


# The Ollama Chat application URL arguments
ollamaChatArguments = argsValidate(arrayNew( \
    objectNew('name', 'model', 'default', 'phi3'), \
    objectNew('name', 'id', 'type', 'int'), \
    objectNew('name', 'prompt', 'explicit', true) \
))


# The sample prompts
ollamaChatSamplePrompts = arrayNew( \
    'What can you do? Break your answer down by categories and subcategories. Answer in detail.', \
    'What do you know? Break your answer down by categories and subcategories. Answer in detail.' \
)


# Start a new chat
async function ollamaChatStartChat(model, prompt):
    startResponse = systemFetch(objectNew('url', 'start_chat', 'body', jsonStringify(objectNew('model', model, 'prompt', prompt))))
    if startResponse != null:
        startResponse = jsonParse(startResponse)
    endif
    if startResponse != null:
        chatId = objectGet(startResponse, 'id')
        windowSetLocation(argsURL(ollamaChatArguments, objectNew('id', chatId)))
    endif
endfunction


# The Ollama Chat index page
function ollamaChatIndexPage(args):
    model = objectGet(args, 'model')
    prompt = objectGet(args, 'prompt')

    # Render the title
    title = 'Ollama Chat' + if(chatId != null, ' - ' + chatId, '')
    documentSetTitle(title)
    markdownPrint('# ' + title, '')

    # Render the sample links
    markdownPrint('## Example Prompts', '')
    for prompt in ollamaChatSamplePrompts:
        elementModelRender(objectNew( \
            'html', 'p', \
            'elem', formsLinkButtonElements(prompt, systemPartial(ollamaChatStartChat, model, prompt)) \
        ))
    endfor
endfunction


# The Ollama Chat chat page
async function ollamaChatPage(args):
    chatId = objectGet(args, 'id')

    # Fetch the chat
    chatResponse = systemFetch('get_chat?id=' + chatId)
    if chatResponse != null:
        chatResponse = jsonParse(chatResponse)
    endif
    if chatResponse == null:
        title = 'Ollama Chat'
        documentSetTitle(title)
        markdownPrint( \
            argsLink(ollamaChatArguments, 'Back', objectNew('id', null)), \
            '# ' + title, \
            '', \
            '**ERROR:** Unknown chat ID' \
        )
        return
    endif
    model = objectGet(chatResponse, 'model')
    prompt = objectGet(chatResponse, 'prompt')
    response = objectGet(chatResponse, 'response')
    completed = objectGet(chatResponse, 'completed')

    # Render the title
    title = 'Ollama Chat'
    documentSetTitle(title)
    markdownPrint( \
        argsLink(ollamaChatArguments, 'Back', objectNew('id', null)), \
        '', \
        '# ' + title, \
        '' \
    )

    # Render the chat
    markdownPrint( \
        '**Model:** ' + model, \
        '', \
        prompt, \
        '', \
        '-----', \
        '' \
    )
    if !completed:
        markdownPrint('Generating...', '')
        elementModelRender(objectNew( \
            'html', 'p', \
            'elem', formsLinkButtonElements('Stop', systemPartial(ollamaChatPageOnStop, chatId)) \
        ))
    endif
    markdownPrint(response)

    # Chat still running?
    if !completed:
        windowSetTimeout(ollamaChatMain, 500)
    endif
endfunction


# Stop a chat
async function ollamaChatPageOnStop(chatId):
    # Stop the chat
    systemFetch(objectNew('url', 'stop_chat', 'body', jsonStringify(objectNew('id', chatId))))

    # Render main
    ollamaChatMain()
endfunction
